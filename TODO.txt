
# Stepher

# governors

No ties.

Bad character added.


### nes

Also, update this data with the latest information from 2024 election. Leave out any variables which you think are problematic. Consider adding some variables (or maybe not). Check that variable possible values, like education, have not changed.



### polls 

Provide URL in documentation.

Add another paragraph, perhaps to details, which describes the election, how it looked, final result, et cetera.

Variable descriptions end with a period and should include the possible values, at least in a case of charater/factor variables with fewer than 6 or so allowed values.

approve values should be Approve, Disapprove, Do Not Know.

Your job to understand what each variable and then document.

"a Florida Senate election survey. " Taken on what date? But what organization?

Are variable names in the Description or Details quoted? Backticked? Nothing? Not sure.

We need to add a dataset which corresponds to the polls dataset which is used in the primer. Maybe October 2024? Must have other variables we like. SS: Done

Change `gender` to `sex`.

Can you find a better treatment? A variable with two values that, even though it was not randomly assigned, you could at least imagine, manipulating. Example: "married" with TRUE/FALSE values.

### polls

* outcome: response
* 2 character: gender
* 3 to 6 character: education
* numeric: turnout_score
* treatment: ?


### ces

Update for latest information. 

* 2 character: sex
* 3 to 6 character: education or ideology
* numeric: faminc
* treatment: voted

# Background Information

* We need to expand the datasets which are used in the primer so that each has:
  
  + at least one categorical character variable which takes on exactly two values.
  + at least one categorical character variable which takes on at least 3, but no more than 6 values.
  + at least one numeric values with a non-absurd distribution
  + at least one character variable with two values which might plausibly be discussed as a treatment variable, i.e., something which, at least in theory, we might manipulate. This might need to be fake, but will clearly be noted as such on the help page. I hope that none of them have to be fake!


## Data Details

For each data set here, list the variable which meets each of the requirements listed above

### nhanes

* 2 character: sex
* 3 to 6 character: race or education
* numeric: bmi
* treatment: diabetes

### nes

* 2 character: sex
* 3 to 6 character: region
* numeric: age
* treatment: voted

### shaming (not that many variables available)

* 2 character: sex
* 3 to 6 character: ?
* numeric: age
* treatment: ? (Nice to have a variable with two possible values which might be considered a treatment.)



### governors

* 2 character: sex
* 3 to 6 character: region
* numeric: election_age
* treatment: status

### trains

DK: Not yet. Add the data for individual questions to the train data. That means adding a column for "question", with settings which include "overall". 

* 2 character: sex
* 3 to 6 character: race
* numeric: att_start
* treatment: liberal






### college SS: object not found

* 2 character: 
* 3 to 6 character:
* numeric:
* treatment: 

### stops

* 2 character: sex
* 3 to 6 character: race
* numeric: age
* treatment: arrested


### Preceptor

* For census we want tracts not counties.

* Why doesn't help(package = "primer.data") pull up links which work? Shouldn't that page also include the new census data?

* ?stops works but ?census does not.

* Key question: Which variables??? Census is overwhelming. Census is hard to use. Find a cool plot and get the variables for that!

* Add some data for class examples, like resume.csv and Tennessee STAR. Investigate why the STAR data seems wrong.

* Revisit the connectedness data.
  - We have copies of the NYT article in the bootcamp repo. Where should we keep that so that students have easy access?
  - Would be nice to add income data so that we can reproduce some of the scatter plots from that article.
  - Might be nice to add some other variables. Even other versions of connectedness would allow us to test the robustness of our main finding.

* Consider deleting unused data

### Improvements

* Drop some data, like names.csv, which we no longer use for the class.

* Look at: https://upworthy.natematias.com/. Pick one data set which you think is cool. Add it to the package. Think about stuff which might be valuable in the chapters, obviously.

* Learn about making test cases from [R Packages](https://r-pkgs.org/tests.html) and add at least one test case for each data set. (Be smart in making these. It is OK to have a test case which tests the number of rows in trains because trains will always (?) have 115 rows. It would be bad (or maybe not?) to have a test case like that for cces since the number of rows for will change once we add next year's data to it.) The definition of a "careful tour" is that you have looked at make_* for a data set, regenerated it, and added at least two test cases about it. You should certainly use any current stopifnot() as test cases and then remove them from the make_* files.

* Transform all the make_ scripts into functions --- I think this is more professional --- which, by default, just return the data. There is an argument for having these functions also install the new data in the package, but the value of that argument  is false by default.

* Should we re-create all the data sets each time we run R CMD package check? This would not take too much time and would ensure that everything is ship-shape.

* Create better stickers with hexSticker package.


### Data Sets

* Need some business data sets, especially ones with real randomized testing. Maybe A/B testing of some sort.

* Non-political science data:

 - NYC taxi and limousine trip records (https://registry.opendata.aws/nyc-tlc-trip-records-pds/)
 - College major & income (https://github.com/rfordatascience/tidytuesday/tree/master/data/2018/2018-10-16)
 - Science experiment: https://science.sciencemag.org/content/358/6364/776/tab-figures-data
 - Called `police`. [Open police data](https://openpolicing.stanford.edu/data/). Something with millions of rows and, ideally, geographic coordinates. We won't include this data in our repo. Instead, the make_police.R script will download and process it. Ideally, we can get the final police.rda to be less than 100 meg so that we don't need to turn on git-lfs again.
 - World Values Survey: http://www.worldvaluessurvey.org/wvs.jsp


