* Weird behavior with data(). -- [Only occurs when working on a package that includes data sets. Other people installing/loading it don't see it.]

* Documentation for ?mail.

* Decide when, if ever, we should use factors. Maybe never? -- [See instructions. Only factors if a variable is categorical and has a natural order. If something is just categorical, keep it a character variable.]

* Decide when we use 0/1 and when we use yes/no or true/false or whatever. -- [Only 0/1 when it's likely to be used as outcome variable. Makes it easier to see what's relevant, and having less 0/1 variables looks more interesting.]

* Get rid of word Control, if possible. -- [Done for mail]

* Add data from this page: https://crime-data-explorer.app.cloud.gov/downloads-and-docs. A few ready-to-use data set from this source can also be found here: https://crimebythenumbers.com/. Pick a few interesting variables, ideally murder-related stuff. For several years.

* CCES interim update https://twitter.com/b_schaffner/status/1375481885351100419

* Create a cool plot for primer.data homepage using primer.data data set. Maybe republican vote by income. Or (better?) ideology by income.

* Add this data: https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/HUUEGI



### Improvements

* Add the data for individual questions to the train data. That means adding a column for "question", with settings which include "overall". Or maybe we need two train data sets: the current one and trains_detailed?

* Learn about making test cases from [R Packages](https://r-pkgs.org/tests.html) and add at least one test case for each data set. (Be smart in making these. It is OK to have a test case which tests the number of rows in trains because trains will always (?) have 115 rows. It would be bad (or maybe not?) to have a test case like that for cces since the number of rows for will change once we add next year's data to it.) The definition of a "careful tour" is that you have looked at make_* for a data set, regenerated it, and added at least two test cases about it. You should certainly use any current stopifnot() as test cases and then remove them from the make_* files.

* Transform all the make_ scripts into functions --- I think this is more professional --- which, by default, just return the data. There is an argument for having these functions also install the new data in the package, but the valaue of that argument  is false by default.

* Provide instruction in the lower part of this document about the release cycle. Like, first you increment the number, then you update NEWS file, then . . . Or just a link to the instructions in R Packages.

* Add gender column to qscores, created by using names, which will probably involve creating a first name column, which we will not keep.

* Should we re-create all the data sets each time we run R CMD package check? This would not take too much time and would ensure that everything is ship-shape.

* pkgdown

  - Start using a release and development branch?

  - Look for nice themes or yaml options

  - Nicer graphics on home page.

  - Instead, we could have an "Article" which provided a list of all the tibbles along with the one paragraph description. Then, the front page could just have a basic blurb and one nice graphic.

* After semester: change "Control" to "No Postcard" in shaming$treatment. Makes clear that "control" is a conceptual category. There does not need to be a level called "Control".

* Create better stickers with hexSticker package.


### Data Sets

* Science experiment: https://science.sciencemag.org/content/358/6364/776/tab-figures-data

* Need something from MB's work on slavery. Ultimate use may just be in making an example for the maps appendix, which should be longer.

* Called `congress`. Something about the results of US congressional elections over several election cycles. 538? Really want this to include some measure of campaign spending so we can discuss a (potential) causal effect. Didn't they have a model which they used for the 2018 election? If they estimated a model, they must have some data.

* Called `police`. [Open police data](https://openpolicing.stanford.edu/data/). Something with millions of rows and, ideally, geographic coordinates. We won't include this data in our repo. Instead, the make_police.R script will download and process it. Ideally, we can get the final police.rda to be less than 100 meg so that we don't need to turn on git-lfs again.

* Called `nominate`. DW NOMINATE from VoteView project: https://www.voteview.com/data

* World Values Survey: http://www.worldvaluessurvey.org/wvs.jsp


